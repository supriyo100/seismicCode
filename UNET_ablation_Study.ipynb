{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading completed\n",
      "segregation inti......\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import mat73\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    \n",
    "data_dict=mat73.loadmat(\"D:/Supriyo/onedrive/OneDrive - iitkgp.ac.in/Sanjay_unet/vi.mat\")\n",
    "loc=np.load(\"D:/Supriyo/onedrive/OneDrive - iitkgp.ac.in/Sanjay_unet/locations.npy\")\n",
    "print(\"Data loading completed\")\n",
    "data=data_dict['vi']\n",
    "x_temp=[]\n",
    "print(\"segregation inti......\")\n",
    "for i in range(len(loc)):\n",
    "    \n",
    "    temp=data[:,loc[i][0]:loc[i][1]+1]\n",
    "    sh=np.shape(temp)\n",
    "    i,j=0,0\n",
    "    while i<=sh[0] and j<=sh[1]:\n",
    "        x_temp.append(temp[i:i+128,j:j+128])\n",
    "        i+=128\n",
    "        j+=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "\n",
    "#EDGE Loss TV+sobel\n",
    "def sobel_edges(image):\n",
    "    # Define Sobel filters\n",
    "    sobel_x = tf.constant([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=tf.float32)\n",
    "    sobel_y = tf.constant([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=tf.float32)\n",
    "\n",
    "    # Calculate Sobel gradients in x and y directions\n",
    "    grad_x = tf.nn.conv2d(image, sobel_x[..., tf.newaxis, tf.newaxis], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    grad_y = tf.nn.conv2d(image, sobel_y[..., tf.newaxis, tf.newaxis], strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    # Compute magnitude of gradients\n",
    "    magnitude = tf.sqrt(grad_x ** 2 + grad_y ** 2)\n",
    "\n",
    "    return magnitude\n",
    "\n",
    "def weighted_TV_p_loss(y_true, y_pred, p=0.9):\n",
    "    loss = tf.reduce_sum(tf.abs(y_true - y_pred) ** p)\n",
    "    return loss\n",
    "\n",
    "def edge_loss(y_true, y_pred, sobel_weight, tv_weight, tv_p):\n",
    "    # Calculate Sobel edges for y_true and y_pred\n",
    "    sobel_true = sobel_edges(y_true)\n",
    "    sobel_pred = sobel_edges(y_pred)\n",
    "\n",
    "    # Calculate the element-wise difference between Sobel edges\n",
    "    sobel_difference = tf.abs(sobel_true - sobel_pred)\n",
    "\n",
    "    # Calculate weighted Sobel edge loss\n",
    "    weighted_sobel_loss = sobel_weight * tf.reduce_mean(sobel_difference)\n",
    "\n",
    "    # Calculate weighted TV_p loss\n",
    "    tv_loss = weighted_TV_p_loss(y_true, y_pred, tv_p)\n",
    "\n",
    "    # Combine the two losses\n",
    "    edge_loss = weighted_sobel_loss + tv_weight * tv_loss\n",
    "\n",
    "    return edge_loss\n",
    "\n",
    "# comined Loss MSE + SSIM\n",
    "def combined_loss_mse_ssim(y_true, y_pred, ssim_weight=0.5):\n",
    "    # Calculate SSIM loss\n",
    "    ssim_loss = 1 - tfa.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "    # Calculate MSE loss\n",
    "    mse_loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Combine both losses with weights\n",
    "    total_loss = ssim_weight * ssim_loss + (1 - ssim_weight) * mse_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "#Fourier Loss\n",
    "def fourierLoss2(y_actual,y_pred):\n",
    "    actual_fft = tf.signal.rfft2d(y_actual)\n",
    "    pred_fft = tf.signal.rfft2d(y_pred)\n",
    "    lossV=tf.math.real(tf.math.reduce_mean(tf.math.square(actual_fft-pred_fft)))\n",
    "    return lossV\n",
    "\n",
    "losses=['mse','mae',tf.keras.losses.CategoricalCrossentropy(),fourierLoss2,weighted_TV_p_loss,edge_loss,combined_loss_mse_ssim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 16  160         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128, 128, 16  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 16  64         ['dropout[0][0]']                \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 16  2320        ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 16)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 64, 64, 16)   0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 64, 64, 16)   0           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.math.abs (TFOpLambda)       (None, 64, 64, 16)   0           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 32)   4640        ['tf.math.abs[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64, 64, 32)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, 64, 32)  128         ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 32)   9248        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 32, 32, 32)   0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 32, 32, 32)   0           ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.abs_1 (TFOpLambda)     (None, 32, 32, 32)   0           ['lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 64)   18496       ['tf.math.abs_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 64)   36928       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 16, 16, 64)   0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 16, 16, 64)   0           ['lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.abs_2 (TFOpLambda)     (None, 16, 16, 64)   0           ['lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 128)  73856       ['tf.math.abs_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16, 16, 128)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 128)  512        ['dropout_3[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 128)  147584      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)   0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 8, 8, 128)    0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 8, 8, 128)    0           ['lambda_6[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.abs_3 (TFOpLambda)     (None, 8, 8, 128)    0           ['lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 256)    295168      ['tf.math.abs_3[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 8, 8, 256)    0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 256)    590080      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 16, 16, 128)  131200     ['conv2d_9[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 16, 16, 128)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 128)  147584      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_4 (TFOpLambda)     (None, 16, 16, 128)  0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 64)  32832       ['tf.math.abs_4[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 32, 32, 128)  256        ['concatenate_1[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 64)   73792       ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 64)   36928       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_5 (TFOpLambda)     (None, 32, 32, 64)   0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 32)  8224        ['tf.math.abs_5[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 64)   0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 64, 64, 64)  128         ['concatenate_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 32)   18464       ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64, 64, 32)   0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 32)   9248        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_6 (TFOpLambda)     (None, 64, 64, 32)   0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 16  2064       ['tf.math.abs_6[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 32  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 128, 128, 32  64         ['concatenate_3[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 16  4624        ['layer_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128, 128, 16  0           ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 16  2320        ['dropout_8[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 1)  17          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,942,225\n",
      "Trainable params: 1,941,745\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def unet(loss,initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9):\n",
    "    inputs = tf.keras.layers.Input((128, 128, 1))\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tf.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    f1 = tf.keras.layers.Lambda(lambda v: tf.signal.fft2d(tf.cast(v, tf.complex64)))(p1)\n",
    "    f1 = tf.keras.layers.Lambda(lambda v: tf.signal.ifft2d(tf.cast(v, tf.complex64)))(f1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(abs(f1))\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    f2 = tf.keras.layers.Lambda(lambda v: tf.signal.fft2d(tf.cast(v, tf.complex64)))(p2)\n",
    "    f2 = tf.keras.layers.Lambda(lambda v: tf.signal.ifft2d(tf.cast(v, tf.complex64)))(f2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(abs(f2))\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = tf.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "    f3 = tf.keras.layers.Lambda(lambda v: tf.signal.fft2d(tf.cast(v, tf.complex64)))(p3)\n",
    "    f3 = tf.keras.layers.Lambda(lambda v: tf.signal.ifft2d(tf.cast(v, tf.complex64)))(f3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(abs(f3))\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = tf.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    f4 = tf.keras.layers.Lambda(lambda v: tf.signal.fft2d(tf.cast(v, tf.complex64)))(p4)\n",
    "    f4 = tf.keras.layers.Lambda(lambda v: tf.signal.ifft2d(tf.cast(v, tf.complex64)))(f4)\n",
    "\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(abs(f4))\n",
    "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    # Expansive path\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(abs(c6))\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    u7 = tf.keras.layers.LayerNormalization()(u7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(abs(c7))\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    u8 = tf.keras.layers.LayerNormalization()(u8)\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(abs(c8))\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "    u9 = tf.keras.layers.LayerNormalization()(u9)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='softmax')(c9)\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    # Learning Rate Decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=True\n",
    "    )\n",
    "  \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model = unet(loss='mse')  # Specify the loss function here\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 128, 128, 16  160         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 128, 128, 16  0           ['conv2d_19[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 16  64         ['dropout_9[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 128, 128, 16  2320        ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 16)  0           ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, 64, 64, 16)   0           ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, 64, 64, 16)   0           ['lambda_8[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.abs_7 (TFOpLambda)     (None, 64, 64, 16)   0           ['lambda_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 64, 64, 32)   4640        ['tf.math.abs_7[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 64, 64, 32)   0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 32)  128         ['dropout_10[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 64, 64, 32)   9248        ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)             (None, 32, 32, 32)   0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)             (None, 32, 32, 32)   0           ['lambda_10[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_8 (TFOpLambda)     (None, 32, 32, 32)   0           ['lambda_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 32, 32, 64)   18496       ['tf.math.abs_8[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 32, 32, 64)   0           ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 64)  256         ['dropout_11[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)  0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)             (None, 16, 16, 64)   0           ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_13 (Lambda)             (None, 16, 16, 64)   0           ['lambda_12[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_9 (TFOpLambda)     (None, 16, 16, 64)   0           ['lambda_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 128)  73856       ['tf.math.abs_9[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 16, 16, 128)  0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 128)  512        ['dropout_12[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 128)   0           ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_14 (Lambda)             (None, 8, 8, 128)    0           ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_15 (Lambda)             (None, 8, 8, 128)    0           ['lambda_14[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_10 (TFOpLambda)    (None, 8, 8, 128)    0           ['lambda_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 8, 8, 256)    295168      ['tf.math.abs_10[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 8, 8, 256)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 8, 8, 256)    590080      ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 16, 16, 128)  131200     ['conv2d_28[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_transpose_4[0][0]',     \n",
      "                                                                  'conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 128)  295040      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 16, 16, 128)  0           ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 128)  147584      ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.abs_11 (TFOpLambda)    (None, 16, 16, 128)  0           ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 32, 32, 64)  32832       ['tf.math.abs_11[0][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_5[0][0]',     \n",
      "                                                                  'conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 32, 32, 128)  256        ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 64)   73792       ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 32, 32, 64)   0           ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 32, 32, 64)   36928       ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.abs_12 (TFOpLambda)    (None, 32, 32, 64)   0           ['conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 64, 64, 32)  8224        ['tf.math.abs_12[0][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 64, 64, 64)   0           ['conv2d_transpose_6[0][0]',     \n",
      "                                                                  'conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 64, 64, 64)  128         ['concatenate_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 64, 64, 32)   18464       ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 64, 64, 32)   0           ['conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 64, 64, 32)   9248        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.abs_13 (TFOpLambda)    (None, 64, 64, 32)   0           ['conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 128, 128, 16  2064       ['tf.math.abs_13[0][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 128, 128, 32  0           ['conv2d_transpose_7[0][0]',     \n",
      "                                )                                 'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 128, 128, 32  64         ['concatenate_7[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 128, 128, 16  4624        ['layer_normalization_5[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 128, 128, 16  0           ['conv2d_35[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 128, 128, 16  2320        ['dropout_17[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 128, 128, 1)  17          ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,942,225\n",
      "Trainable params: 1,941,745\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def unet(loss,initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9):\n",
    "    inputs = tf.keras.layers.Input((128, 128, 1))\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tf.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    f1 = tf.keras.layers.Lambda(lambda v: tf.signal.fft2d(tf.cast(v, tf.complex64)))(p1)\n",
    "    f1 = tf.keras.layers.Lambda(lambda v: tf.signal.ifft2d(tf.cast(v, tf.complex64)))(f1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(abs(f1))\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    f2 = tf.keras.layers.Lambda(lambda v: tf.signal.fft2d(tf.cast(v, tf.complex64)))(p2)\n",
    "    f2 = tf.keras.layers.Lambda(lambda v: tf.signal.ifft2d(tf.cast(v, tf.complex64)))(f2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(abs(f2))\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = tf.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "    f3 = tf.keras.layers.Lambda(lambda v: tf.signal.fft2d(tf.cast(v, tf.complex64)))(p3)\n",
    "    f3 = tf.keras.layers.Lambda(lambda v: tf.signal.ifft2d(tf.cast(v, tf.complex64)))(f3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(abs(f3))\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = tf.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    f4 = tf.keras.layers.Lambda(lambda v: tf.signal.fft2d(tf.cast(v, tf.complex64)))(p4)\n",
    "    f4 = tf.keras.layers.Lambda(lambda v: tf.signal.ifft2d(tf.cast(v, tf.complex64)))(f4)\n",
    "\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(abs(f4))\n",
    "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    # Expansive path\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(abs(c6))\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    u7 = tf.keras.layers.LayerNormalization()(u7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(abs(c7))\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    u8 = tf.keras.layers.LayerNormalization()(u8)\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(abs(c8))\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "    u9 = tf.keras.layers.LayerNormalization()(u9)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='softmax')(c9)\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    # Learning Rate Decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=True\n",
    "    )\n",
    "  \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model = unet(loss=losses)  # Specify the loss function here\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "#Loss\n",
    "\n",
    "#EDGE Loss TV+sobel\n",
    "def sobel_edges(image):\n",
    "    # Define Sobel filters\n",
    "    sobel_x = tf.constant([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=tf.float32)\n",
    "    sobel_y = tf.constant([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=tf.float32)\n",
    "\n",
    "    # Calculate Sobel gradients in x and y directions\n",
    "    grad_x = tf.nn.conv2d(image, sobel_x[..., tf.newaxis, tf.newaxis], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    grad_y = tf.nn.conv2d(image, sobel_y[..., tf.newaxis, tf.newaxis], strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    # Compute magnitude of gradients\n",
    "    magnitude = tf.sqrt(grad_x ** 2 + grad_y ** 2)\n",
    "\n",
    "    return magnitude\n",
    "\n",
    "def weighted_TV_p_loss(y_true, y_pred, p=0.9):\n",
    "    loss = tf.reduce_sum(tf.abs(y_true - y_pred) ** p)\n",
    "    return loss\n",
    "\n",
    "def edge_loss(y_true, y_pred, sobel_weight, tv_weight, tv_p):\n",
    "    # Calculate Sobel edges for y_true and y_pred\n",
    "    sobel_true = sobel_edges(y_true)\n",
    "    sobel_pred = sobel_edges(y_pred)\n",
    "\n",
    "    # Calculate the element-wise difference between Sobel edges\n",
    "    sobel_difference = tf.abs(sobel_true - sobel_pred)\n",
    "\n",
    "    # Calculate weighted Sobel edge loss\n",
    "    weighted_sobel_loss = sobel_weight * tf.reduce_mean(sobel_difference)\n",
    "\n",
    "    # Calculate weighted TV_p loss\n",
    "    tv_loss = weighted_TV_p_loss(y_true, y_pred, tv_p)\n",
    "\n",
    "    # Combine the two losses\n",
    "    edge_loss = weighted_sobel_loss + tv_weight * tv_loss\n",
    "\n",
    "    return edge_loss\n",
    "\n",
    "# comined Loss MSE + SSIM\n",
    "def combined_loss_mse_ssim(y_true, y_pred, ssim_weight=0.5):\n",
    "    # Calculate SSIM loss\n",
    "    ssim_loss = 1 - tfa.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "    # Calculate MSE loss\n",
    "    mse_loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # Combine both losses with weights\n",
    "    total_loss = ssim_weight * ssim_loss + (1 - ssim_weight) * mse_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "#Fourier Loss\n",
    "def fourierLoss2(y_actual,y_pred):\n",
    "    actual_fft = tf.signal.rfft2d(y_actual)\n",
    "    pred_fft = tf.signal.rfft2d(y_pred)\n",
    "    lossV=tf.math.real(tf.math.reduce_mean(tf.math.square(actual_fft-pred_fft)))\n",
    "    return lossV\n",
    "\n",
    "losses=['mse','mae',tf.keras.losses.CategoricalCrossentropy(),fourierLoss2,weighted_TV_p_loss,edge_loss,combined_loss_mse_ssim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_history = []\n",
    "val_accuracy_history = []\n",
    "val_precision_history = []\n",
    "val_recall_history = []\n",
    "model=unet()\n",
    "def on_epoch_end(epoch, logs={}):\n",
    "    val_loss = logs.get('val_loss')\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    if len(val_loss_history) > patience:\n",
    "        min_loss = min(val_loss_history[-patience:])\n",
    "        max_loss = max(val_loss_history[-patience:])\n",
    "        if max_loss - min_loss < early_stopping_loss:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch + 1} as val_loss change < {early_stopping_loss}\")\n",
    "            model.stop_training = True\n",
    "\n",
    "    # Evaluate the model on validation data after each epoch\n",
    "    X_val_pred = model.predict(X_val)\n",
    "    X_val_pred = np.round(X_val_pred)  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = accuracy_score(X_val.reshape(-1), X_val_pred.reshape(-1))\n",
    "    precision = precision_score(X_val.reshape(-1), X_val_pred.reshape(-1), average='micro')\n",
    "    recall = recall_score(X_val.reshape(-1), X_val_pred.reshape(-1), average='micro')\n",
    "\n",
    "    # Append to history lists\n",
    "    val_accuracy_history.append(accuracy)\n",
    "    val_precision_history.append(precision)\n",
    "    val_recall_history.append(recall)\n",
    "\n",
    "    # Print the metrics after each epoch\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"{steps_per_epoch}/{steps_per_epoch} [==============================] - {logs.get('loss'):.4f} - accuracy: {accuracy:.4f} - precision: {precision:.4f} - recall: {recall:.4f} - val_loss: {val_loss:.4f}\")\n",
    "\n",
    "# ... (Rest of the code)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    X_train,  # Use different variables for input and output\n",
    "    validation_data=(X_val, X_val),  # Add validation data\n",
    "    callbacks=[model_checkpoint_callback, tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)],\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    steps_per_epoch=steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 128, 128, 16  160         ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 128, 128, 16  0           ['conv2d_19[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 16  64         ['dropout_9[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 128, 128, 16  2320        ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 16)  0           ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, 64, 64, 16)   0           ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, 64, 64, 16)   0           ['lambda_8[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.abs_7 (TFOpLambda)     (None, 64, 64, 16)   0           ['lambda_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 64, 64, 32)   4640        ['tf.math.abs_7[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 64, 64, 32)   0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 32)  128         ['dropout_10[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 64, 64, 32)   9248        ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)             (None, 32, 32, 32)   0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)             (None, 32, 32, 32)   0           ['lambda_10[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_8 (TFOpLambda)     (None, 32, 32, 32)   0           ['lambda_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 32, 32, 64)   18496       ['tf.math.abs_8[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 32, 32, 64)   0           ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 64)  256         ['dropout_11[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)  0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)             (None, 16, 16, 64)   0           ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_13 (Lambda)             (None, 16, 16, 64)   0           ['lambda_12[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_9 (TFOpLambda)     (None, 16, 16, 64)   0           ['lambda_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 128)  73856       ['tf.math.abs_9[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 16, 16, 128)  0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 128)  512        ['dropout_12[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 128)   0           ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_14 (Lambda)             (None, 8, 8, 128)    0           ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_15 (Lambda)             (None, 8, 8, 128)    0           ['lambda_14[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.abs_10 (TFOpLambda)    (None, 8, 8, 128)    0           ['lambda_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 8, 8, 256)    295168      ['tf.math.abs_10[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 8, 8, 256)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 8, 8, 256)    590080      ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 16, 16, 128)  131200     ['conv2d_28[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_transpose_4[0][0]',     \n",
      "                                                                  'conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 128)  295040      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 16, 16, 128)  0           ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 128)  147584      ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.abs_11 (TFOpLambda)    (None, 16, 16, 128)  0           ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 32, 32, 64)  32832       ['tf.math.abs_11[0][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_5[0][0]',     \n",
      "                                                                  'conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 32, 32, 128)  256        ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 64)   73792       ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 32, 32, 64)   0           ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 32, 32, 64)   36928       ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.abs_12 (TFOpLambda)    (None, 32, 32, 64)   0           ['conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 64, 64, 32)  8224        ['tf.math.abs_12[0][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 64, 64, 64)   0           ['conv2d_transpose_6[0][0]',     \n",
      "                                                                  'conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 64, 64, 64)  128         ['concatenate_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 64, 64, 32)   18464       ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 64, 64, 32)   0           ['conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 64, 64, 32)   9248        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.abs_13 (TFOpLambda)    (None, 64, 64, 32)   0           ['conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 128, 128, 16  2064       ['tf.math.abs_13[0][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 128, 128, 32  0           ['conv2d_transpose_7[0][0]',     \n",
      "                                )                                 'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 128, 128, 32  64         ['concatenate_7[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 128, 128, 16  4624        ['layer_normalization_5[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 128, 128, 16  0           ['conv2d_35[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 128, 128, 16  2320        ['dropout_17[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 128, 128, 1)  17          ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,942,225\n",
      "Trainable params: 1,941,745\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "94/94 [==============================] - 451s 5s/step - loss: 0.3034 - val_loss: 0.3060\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 455s 5s/step - loss: 0.3034 - val_loss: 0.3060\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 452s 5s/step - loss: 0.3034 - val_loss: 0.3060\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 451s 5s/step - loss: 0.3034 - val_loss: 0.3060\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 462s 5s/step - loss: 0.3034 - val_loss: 0.3060\n",
      "Epoch 6/100\n",
      "40/94 [===========>..................] - ETA: 3:55 - loss: 0.3050"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m early_stopping_callback\u001b[39m.\u001b[39mon_epoch_end \u001b[39m=\u001b[39m on_epoch_end\n\u001b[0;32m     58\u001b[0m \u001b[39m# Assuming X_train and X_val are your training and validation datasets, respectively\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m history \u001b[39m=\u001b[39m model[i]\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     60\u001b[0m     tf\u001b[39m.\u001b[39;49mexpand_dims(X_train[:], axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m     61\u001b[0m     tf\u001b[39m.\u001b[39;49mexpand_dims(X_train[:], axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),  \u001b[39m# Use different variables for input and output\u001b[39;49;00m\n\u001b[0;32m     62\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(tf\u001b[39m.\u001b[39;49mexpand_dims(X_val[:], axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), tf\u001b[39m.\u001b[39;49mexpand_dims(X_val[:], axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)),  \u001b[39m# Add validation data\u001b[39;49;00m\n\u001b[0;32m     63\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback, early_stopping_callback],  \u001b[39m# Add early stopping callback\u001b[39;49;00m\n\u001b[0;32m     64\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlosses[i]\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m outfile:\n\u001b[0;32m     68\u001b[0m     json\u001b[39m.\u001b[39mdump(history\u001b[39m.\u001b[39mhistory, outfile)\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Supriyo\\onedrive\\OneDrive - iitkgp.ac.in\\Thesis Concrete Work\\UNET-FFT\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_t = []\n",
    "for i in x_temp:\n",
    "    if np.shape(i) == (128, 128):\n",
    "        x_t.append(i)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data = []\n",
    "for i in x_t:\n",
    "    data.append(scaler.fit_transform(i))\n",
    "\n",
    "# Convert data to numpy array\n",
    "data = np.array(data)\n",
    "\n",
    "# Split your training data into training and validation sets\n",
    "X_train, X_val, _, _ = train_test_split(data, data, test_size=0.1, random_state=42)\n",
    "\n",
    "model = [0, 0, 0, 0, 0, 0]\n",
    "early_stopping_loss = 4.2e-4  # Loss threshold for early stopping\n",
    "patience = 5  # Number of epochs with no significant loss improvement before stopping\n",
    "\n",
    "# Assuming 'losses' is a list of different loss functions\n",
    "for i in range(len(losses)):\n",
    "    model[i] = unet(losses[i])\n",
    "    print(model[i].summary())\n",
    "\n",
    "    epoch = 0\n",
    "    checkpoint_path = f\"./cp-{losses[i]}-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Calculate the steps per epoch based on your dataset size and batch size\n",
    "    batch_size = 32  # Set your desired batch size here\n",
    "    steps_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        save_weights_only=True,\n",
    "        mode='min',\n",
    "        save_freq=5 * steps_per_epoch,  # Save after every 5 epochs\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = tf.keras.callbacks.Callback()  # Custom Callback for Early Stopping\n",
    "\n",
    "    val_loss_history = []\n",
    "\n",
    "    def on_epoch_end(epoch, logs={}):\n",
    "        val_loss = logs.get('val_loss')\n",
    "        val_loss_history.append(val_loss)\n",
    "        \n",
    "        if len(val_loss_history) > patience:\n",
    "            min_loss = min(val_loss_history[-patience:])\n",
    "            max_loss = max(val_loss_history[-patience:])\n",
    "            if max_loss - min_loss < early_stopping_loss:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch + 1} as val_loss change < {early_stopping_loss}\")\n",
    "                model[i].stop_training = True\n",
    "\n",
    "    early_stopping_callback.on_epoch_end = on_epoch_end\n",
    "\n",
    "    # Assuming X_train and X_val are your training and validation datasets, respectively\n",
    "    history = model[i].fit(\n",
    "        tf.expand_dims(X_train[:], axis=-1),\n",
    "        tf.expand_dims(X_train[:], axis=-1),  # Use different variables for input and output\n",
    "        validation_data=(tf.expand_dims(X_val[:], axis=-1), tf.expand_dims(X_val[:], axis=-1)),  # Add validation data\n",
    "        callbacks=[model_checkpoint_callback, early_stopping_callback],  # Add early stopping callback\n",
    "        epochs=100\n",
    "    )\n",
    "\n",
    "    with open(f\"{losses[i]}.json\", \"w\") as outfile:\n",
    "        json.dump(history.history, outfile)\n",
    "\n",
    "    model[i].save(f\"model_{losses[i]}.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
